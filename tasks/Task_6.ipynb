{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "Данные в [архиве](https://drive.google.com/file/d/15o7fdxTgndoy6K-e7g8g1M2-bOOwqZPl/view?usp=sharing). В нём два файла:\n",
    "- `news_train.txt` тренировочное множество\n",
    "- `news_test.txt` тестировочное множество\n",
    "\n",
    "С некоторых новостных сайтов были загружены тексты новостей за период  несколько лет, причем каждая новость принаделжит к какой-то рубрике: `science`, `style`, `culture`, `life`, `economics`, `business`, `travel`, `forces`, `media`, `sport`.\n",
    "\n",
    "В каждой строке файла содержится метка рубрики, заголовок новостной статьи и сам текст статьи, например:\n",
    "\n",
    ">    **sport**&nbsp;&lt;tab&gt;&nbsp;**Сборная Канады по хоккею разгромила чехов**&nbsp;&lt;tab&gt;&nbsp;**Сборная Канады по хоккею крупно об...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача\n",
    "\n",
    "1. Обработать данные, получив для каждого текста набор токенов\n",
    "Обработать токены с помощью (один вариант из трех):\n",
    "    - pymorphy2\n",
    "    - русского [snowball стеммера](https://www.nltk.org/howto/stem.html)\n",
    "    - [SentencePiece](https://github.com/google/sentencepiece) или [Huggingface Tokenizers](https://github.com/huggingface/tokenizers)\n",
    "    \n",
    "    \n",
    "2. Обучить word embeddings (fastText, word2vec, gloVe) на тренировочных данных. Можно использовать [gensim](https://radimrehurek.com/gensim/models/word2vec.html) . Продемонстрировать семантические ассоциации. \n",
    "\n",
    "3. Реализовать алгоритм классификации, посчитать точноть на тестовых данных, подобрать гиперпараметры. Метод векторизации выбрать произвольно - можно использовать $tf-idf$ с понижением размерности (см. scikit-learn), можно использовать обученные на предыдущем шаге векторные представления, можно использовать [предобученные модели](https://rusvectores.org/ru/models/). Имейте ввиду, что простое \"усреднение\" токенов в тексте скорее всего не даст положительных результатов. Нужно реализовать два алгоритмов из трех:\n",
    "     - SVM\n",
    "     - наивный байесовский классификатор\n",
    "     - логистическая регрессия\n",
    "    \n",
    "\n",
    "4.* Реализуйте классификацию с помощью нейросетевых моделей. Например [RuBERT](http://docs.deeppavlov.ai/en/master/features/models/bert.html) или [ELMo](https://rusvectores.org/ru/models/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lines = list(open('./news_train.txt', 'r', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Рубрика</th>\n",
       "      <th>Заголовок</th>\n",
       "      <th>Текст</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sport</td>\n",
       "      <td>Овечкин пожертвовал детской хоккейной школе ав...</td>\n",
       "      <td>Нападающий «Вашингтон Кэпиталз» Александр Овеч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culture</td>\n",
       "      <td>Рекордно дорогую статую майя признали подделкой</td>\n",
       "      <td>Власти Мексики объявили подделкой статую майя,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science</td>\n",
       "      <td>Samsung представила флагман в защищенном корпусе</td>\n",
       "      <td>Южнокорейская Samsung анонсировала защищенную ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>С футболиста «Спартака» сняли четырехматчевую ...</td>\n",
       "      <td>Контрольно-дисциплинарный комитет (КДК) РФС сн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media</td>\n",
       "      <td>Hopes &amp; Fears объединится с The Village</td>\n",
       "      <td>Интернет-издание Hopes &amp; Fears объявило о свое...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Рубрика                                          Заголовок  \\\n",
       "0    sport  Овечкин пожертвовал детской хоккейной школе ав...   \n",
       "1  culture    Рекордно дорогую статую майя признали подделкой   \n",
       "2  science   Samsung представила флагман в защищенном корпусе   \n",
       "3    sport  С футболиста «Спартака» сняли четырехматчевую ...   \n",
       "4    media            Hopes & Fears объединится с The Village   \n",
       "\n",
       "                                               Текст  \n",
       "0  Нападающий «Вашингтон Кэпиталз» Александр Овеч...  \n",
       "1  Власти Мексики объявили подделкой статую майя,...  \n",
       "2  Южнокорейская Samsung анонсировала защищенную ...  \n",
       "3  Контрольно-дисциплинарный комитет (КДК) РФС сн...  \n",
       "4  Интернет-издание Hopes & Fears объявило о свое...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/news_train.txt', sep='\\t',header=None )\n",
    "df_test = pd.read_csv('../data/news_test.txt', sep='\\t',header=None )\n",
    "df_train.columns = ['Рубрика', 'Заголовок', 'Текст']\n",
    "df_test.columns = ['Рубрика', 'Заголовок', 'Текст']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Обработать данные, получив для каждого текста набор токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Рубрика</th>\n",
       "      <th>Заголовок</th>\n",
       "      <th>Текст</th>\n",
       "      <th>Токены</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sport</td>\n",
       "      <td>Овечкин пожертвовал детской хоккейной школе ав...</td>\n",
       "      <td>Нападающий «Вашингтон Кэпиталз» Александр Овеч...</td>\n",
       "      <td>[Нападающий, «, Вашингтон, Кэпиталз, », Алекса...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culture</td>\n",
       "      <td>Рекордно дорогую статую майя признали подделкой</td>\n",
       "      <td>Власти Мексики объявили подделкой статую майя,...</td>\n",
       "      <td>[Власти, Мексики, объявили, подделкой, статую,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science</td>\n",
       "      <td>Samsung представила флагман в защищенном корпусе</td>\n",
       "      <td>Южнокорейская Samsung анонсировала защищенную ...</td>\n",
       "      <td>[Южнокорейская, Samsung, анонсировала, защищен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>С футболиста «Спартака» сняли четырехматчевую ...</td>\n",
       "      <td>Контрольно-дисциплинарный комитет (КДК) РФС сн...</td>\n",
       "      <td>[Контрольно-дисциплинарный, комитет, (, КДК, )...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media</td>\n",
       "      <td>Hopes &amp; Fears объединится с The Village</td>\n",
       "      <td>Интернет-издание Hopes &amp; Fears объявило о свое...</td>\n",
       "      <td>[Интернет-издание, Hopes, &amp;, Fears, объявило, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Рубрика                                          Заголовок  \\\n",
       "0    sport  Овечкин пожертвовал детской хоккейной школе ав...   \n",
       "1  culture    Рекордно дорогую статую майя признали подделкой   \n",
       "2  science   Samsung представила флагман в защищенном корпусе   \n",
       "3    sport  С футболиста «Спартака» сняли четырехматчевую ...   \n",
       "4    media            Hopes & Fears объединится с The Village   \n",
       "\n",
       "                                               Текст  \\\n",
       "0  Нападающий «Вашингтон Кэпиталз» Александр Овеч...   \n",
       "1  Власти Мексики объявили подделкой статую майя,...   \n",
       "2  Южнокорейская Samsung анонсировала защищенную ...   \n",
       "3  Контрольно-дисциплинарный комитет (КДК) РФС сн...   \n",
       "4  Интернет-издание Hopes & Fears объявило о свое...   \n",
       "\n",
       "                                              Токены  \n",
       "0  [Нападающий, «, Вашингтон, Кэпиталз, », Алекса...  \n",
       "1  [Власти, Мексики, объявили, подделкой, статую,...  \n",
       "2  [Южнокорейская, Samsung, анонсировала, защищен...  \n",
       "3  [Контрольно-дисциплинарный, комитет, (, КДК, )...  \n",
       "4  [Интернет-издание, Hopes, &, Fears, объявило, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "df_train['Токены'] = df_train['Текст'].apply(word_tokenize)\n",
    "df_test['Токены'] = df_test['Текст'].apply(word_tokenize)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import RussianStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "rs = RussianStemmer()\n",
    "sw_r = set(stopwords.words('russian'))\n",
    "sw_e = set(stopwords.words('english'))\n",
    "\n",
    "def preprocessing(words):\n",
    "    new_word_list = []\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word.isalpha() and not (word in sw_r) and not (word in sw_e):\n",
    "                new_word_list.append(rs.stem(word))\n",
    "    return new_word_list\n",
    "\n",
    "\n",
    "df_train['Токены'] = df_train['Токены'].apply(preprocessing)\n",
    "df_test['Токены'] = df_test['Токены'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Рубрика</th>\n",
       "      <th>Заголовок</th>\n",
       "      <th>Текст</th>\n",
       "      <th>Токены</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sport</td>\n",
       "      <td>Овечкин пожертвовал детской хоккейной школе ав...</td>\n",
       "      <td>Нападающий «Вашингтон Кэпиталз» Александр Овеч...</td>\n",
       "      <td>[напада, вашингтон, кэпиталз, александр, овечк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culture</td>\n",
       "      <td>Рекордно дорогую статую майя признали подделкой</td>\n",
       "      <td>Власти Мексики объявили подделкой статую майя,...</td>\n",
       "      <td>[власт, мексик, объяв, подделк, стат, май, про...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science</td>\n",
       "      <td>Samsung представила флагман в защищенном корпусе</td>\n",
       "      <td>Южнокорейская Samsung анонсировала защищенную ...</td>\n",
       "      <td>[южнокорейск, samsung, анонсирова, защищен, ве...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>С футболиста «Спартака» сняли четырехматчевую ...</td>\n",
       "      <td>Контрольно-дисциплинарный комитет (КДК) РФС сн...</td>\n",
       "      <td>[комитет, кдк, рфс, снял, дисквалификац, полуз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media</td>\n",
       "      <td>Hopes &amp; Fears объединится с The Village</td>\n",
       "      <td>Интернет-издание Hopes &amp; Fears объявило о свое...</td>\n",
       "      <td>[hopes, fears, объяв, сво, слиян, сайт, villag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Рубрика                                          Заголовок  \\\n",
       "0    sport  Овечкин пожертвовал детской хоккейной школе ав...   \n",
       "1  culture    Рекордно дорогую статую майя признали подделкой   \n",
       "2  science   Samsung представила флагман в защищенном корпусе   \n",
       "3    sport  С футболиста «Спартака» сняли четырехматчевую ...   \n",
       "4    media            Hopes & Fears объединится с The Village   \n",
       "\n",
       "                                               Текст  \\\n",
       "0  Нападающий «Вашингтон Кэпиталз» Александр Овеч...   \n",
       "1  Власти Мексики объявили подделкой статую майя,...   \n",
       "2  Южнокорейская Samsung анонсировала защищенную ...   \n",
       "3  Контрольно-дисциплинарный комитет (КДК) РФС сн...   \n",
       "4  Интернет-издание Hopes & Fears объявило о свое...   \n",
       "\n",
       "                                              Токены  \n",
       "0  [напада, вашингтон, кэпиталз, александр, овечк...  \n",
       "1  [власт, мексик, объяв, подделк, стат, май, про...  \n",
       "2  [южнокорейск, samsung, анонсирова, защищен, ве...  \n",
       "3  [комитет, кдк, рфс, снял, дисквалификац, полуз...  \n",
       "4  [hopes, fears, объяв, сво, слиян, сайт, villag...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучить word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "tr = list(df_train['Токены'].values)\n",
    "tst = list(df_test['Токены'].values)\n",
    "\n",
    "w2v = Word2Vec(tr + tst, size=50 ,min_count=1, window=5, workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('актрис', 0.9336420297622681),\n",
       " ('режиссер', 0.9168128371238708),\n",
       " ('питт', 0.8717546463012695),\n",
       " ('макэв', 0.8695226311683655),\n",
       " ('крэйг', 0.8681154847145081),\n",
       " ('эджертон', 0.863692045211792),\n",
       " ('аффлек', 0.8572142720222473),\n",
       " ('джеймс', 0.8458917737007141),\n",
       " ('сценарист', 0.8441108465194702),\n",
       " ('карелл', 0.8436678051948547)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=['актер'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('поправк', 0.9613997936248779),\n",
       " ('поправок', 0.9014572501182556),\n",
       " ('постановлен', 0.9008971452713013),\n",
       " ('закон', 0.8829703330993652),\n",
       " ('госдум', 0.8587325215339661),\n",
       " ('внесен', 0.8364836573600769),\n",
       " ('инициатив', 0.8321452140808105),\n",
       " ('законодательств', 0.8228006362915039),\n",
       " ('требован', 0.821120023727417),\n",
       " ('законодательн', 0.8087468147277832)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=['законопроект'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('полномочн', 0.5840857028961182),\n",
       " ('альв', 0.5474891662597656),\n",
       " ('украинеофициальн', 0.5418031811714172),\n",
       " ('червиченк', 0.5274759531021118),\n",
       " ('хунт', 0.5258936882019043),\n",
       " ('штаатскапелл', 0.5244912505149841),\n",
       " ('ксир', 0.523795485496521),\n",
       " ('mlb', 0.5231428742408752),\n",
       " ('автопоезд', 0.5205785632133484),\n",
       " ('обветшан', 0.5083560943603516)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=['генеральн'], negative=['директор'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('медик', 0.7839198112487793),\n",
       " ('исследовател', 0.7757724523544312),\n",
       " ('психолог', 0.7723990082740784),\n",
       " ('сноуд', 0.7616479992866516),\n",
       " ('хамз', 0.7600890398025513),\n",
       " ('долмат', 0.759471595287323),\n",
       " ('кузбасск', 0.7580829858779907),\n",
       " ('студент', 0.7569434642791748),\n",
       " ('признательн', 0.7506290078163147),\n",
       " ('коллег', 0.7470023036003113)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=['журналист', 'учен'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Реализовать алгоритм классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x)\n",
    "vectorizer.fit(list(df_train['Токены'].values) + list(df_test['Токены'].values))\n",
    "\n",
    "idf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_vector(sentence):\n",
    "    n = len(sentence)\n",
    "    vector = np.zeros(50)\n",
    "    for word in sentence:\n",
    "        vector += idf[word] * w2v.wv[word]\n",
    "    return vector / n\n",
    "\n",
    "df_train['Вектор'] = df_train['Токены'].apply(to_vector)\n",
    "df_test['Вектор'] = df_test['Токены'].apply(to_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Рубрика</th>\n",
       "      <th>Заголовок</th>\n",
       "      <th>Текст</th>\n",
       "      <th>Токены</th>\n",
       "      <th>Вектор</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sport</td>\n",
       "      <td>Овечкин пожертвовал детской хоккейной школе ав...</td>\n",
       "      <td>Нападающий «Вашингтон Кэпиталз» Александр Овеч...</td>\n",
       "      <td>[напада, вашингтон, кэпиталз, александр, овечк...</td>\n",
       "      <td>[0.9449942457694782, -2.8987251495099846, 2.59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>culture</td>\n",
       "      <td>Рекордно дорогую статую майя признали подделкой</td>\n",
       "      <td>Власти Мексики объявили подделкой статую майя,...</td>\n",
       "      <td>[власт, мексик, объяв, подделк, стат, май, про...</td>\n",
       "      <td>[0.8885383913926918, -2.270422556930605, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science</td>\n",
       "      <td>Samsung представила флагман в защищенном корпусе</td>\n",
       "      <td>Южнокорейская Samsung анонсировала защищенную ...</td>\n",
       "      <td>[южнокорейск, samsung, анонсирова, защищен, ве...</td>\n",
       "      <td>[-0.5637279943209406, -7.860753782515256, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>С футболиста «Спартака» сняли четырехматчевую ...</td>\n",
       "      <td>Контрольно-дисциплинарный комитет (КДК) РФС сн...</td>\n",
       "      <td>[комитет, кдк, рфс, снял, дисквалификац, полуз...</td>\n",
       "      <td>[0.33258345131283606, -3.3388640676564147, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>media</td>\n",
       "      <td>Hopes &amp; Fears объединится с The Village</td>\n",
       "      <td>Интернет-издание Hopes &amp; Fears объявило о свое...</td>\n",
       "      <td>[hopes, fears, объяв, сво, слиян, сайт, villag...</td>\n",
       "      <td>[-0.4890713593696506, -3.0280836876300934, -1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Рубрика                                          Заголовок  \\\n",
       "0    sport  Овечкин пожертвовал детской хоккейной школе ав...   \n",
       "1  culture    Рекордно дорогую статую майя признали подделкой   \n",
       "2  science   Samsung представила флагман в защищенном корпусе   \n",
       "3    sport  С футболиста «Спартака» сняли четырехматчевую ...   \n",
       "4    media            Hopes & Fears объединится с The Village   \n",
       "\n",
       "                                               Текст  \\\n",
       "0  Нападающий «Вашингтон Кэпиталз» Александр Овеч...   \n",
       "1  Власти Мексики объявили подделкой статую майя,...   \n",
       "2  Южнокорейская Samsung анонсировала защищенную ...   \n",
       "3  Контрольно-дисциплинарный комитет (КДК) РФС сн...   \n",
       "4  Интернет-издание Hopes & Fears объявило о свое...   \n",
       "\n",
       "                                              Токены  \\\n",
       "0  [напада, вашингтон, кэпиталз, александр, овечк...   \n",
       "1  [власт, мексик, объяв, подделк, стат, май, про...   \n",
       "2  [южнокорейск, samsung, анонсирова, защищен, ве...   \n",
       "3  [комитет, кдк, рфс, снял, дисквалификац, полуз...   \n",
       "4  [hopes, fears, объяв, сво, слиян, сайт, villag...   \n",
       "\n",
       "                                              Вектор  \n",
       "0  [0.9449942457694782, -2.8987251495099846, 2.59...  \n",
       "1  [0.8885383913926918, -2.270422556930605, -0.08...  \n",
       "2  [-0.5637279943209406, -7.860753782515256, -0.1...  \n",
       "3  [0.33258345131283606, -3.3388640676564147, 0.9...  \n",
       "4  [-0.4890713593696506, -3.0280836876300934, -1....  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [line for line in df_train['Вектор'].values]\n",
    "y_train = df_train['Рубрика'].values\n",
    "\n",
    "X_test = [line for line in df_test['Вектор'].values]\n",
    "y_test = df_test['Рубрика'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.829"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lg = LogisticRegression(n_jobs=-1)\n",
    "lg.fit(X_train, y_train)\n",
    "\n",
    "(y_test == clf.predict(X_test)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.829"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "(y_test == clf.predict(X_test)).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
